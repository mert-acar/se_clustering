# Data
data:
  dataset_name: CIFAR10
  batch_size: 128 # ignored in cluster training
  sample_per_class: 53 # ignored in autoencoder training
  
model:
  filters: [16, 32, 64, 128]

# Training
train: 
  num_epochs: 200
  learning_rate: 0.00005
  weight_decay: 0

  scheduler_args:
    factor: 0.1
    patience: 4

  criterion_args:
    w_coeff: 1000
    w_self_exp: 0.1

  early_stop: 100
  pretrained_weights: ../logs/AE_CIFAR10/best_state.pt

cluster:
  dims: 12
  alpha: 12
  ro: 0.04
